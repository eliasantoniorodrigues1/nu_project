# nu_project
---

## Projeto de migraÃ§Ã£o de modelo de dados
### Objetivo:
	Recriar o banco de dados original no modelo floco de neve e migra-lo para o esquema estrela.

### Problem Statements

### Problem Statement 1: Gerando consultas SQL

Nssa etapa foi gerado uma consulta para o problema proposto de saldo mensal das contas. A consulta e o csv gerado estÃ£o armazenados no caminho abaixo:

**\Nubank_Analytics_Engineer_Case_4.0\Problem Statement\1_Problem Statement**

**SGBD -> MySQL (default engine).***

â€¢	Amount_Balance_Account.sql
â€¢	Balance Account Monthly.csv
â€¢	Necessary Inputs.txt

Foi utilizado a uniÃ£o de trÃªs tabelas para a criaÃ§Ã£o de uma tabela de cÃ¡lculo (CTE). Essa tabela Ã© ligada com a tabela de clientes para trazer o account_id e o nome do cliente.
As colunas *Total Transfer In*, *Total Transfer Out* e *Account Monthly Balance* sÃ£o calculadas na CTE e levam em consideraÃ§Ã£o as movimentaÃ§Ãµes do pix tambÃ©m.

**Obs.: Para esse problema nÃ£o foi usado a tabela de investimentos.**

**Query**

![image](https://user-images.githubusercontent.com/49626719/175798981-76f8571d-9e85-4143-9b35-0e15c0a21745.png)

**Result**

![image](https://user-images.githubusercontent.com/49626719/175799145-659eda87-6878-4453-88eb-18f785b8723f.png)


### Problem Statement 2:

***a. Proposta para mudanÃ§a do modelo de dados original:***

***Snow Flake***

 ![image](https://user-images.githubusercontent.com/49626719/175799521-74982800-a6b6-46f2-8227-54621aecfb63.png)



  ***Star Schema***
  
 ![image](https://user-images.githubusercontent.com/49626719/175793235-fa3da6f6-927c-46fa-b82d-2f5c9bf37ef6.png)


***b. O modelo floco de neve nÃ£o Ã© o mais recomendado pois possui um nÃ­vel maior de normalizaÃ§Ã£o dos dados, o que pode gerar lentidÃ£o devido ao ecesso de relacionamentos entre tabelas do modelo para alcanÃ§ar um determinado tipo de resultado.
A ideia Ã© consolidar algumas tabelas do modelo, criando agregaÃ§Ã£o de campos.***

### DimensÃµes propostas para o modelo estrela:

**DimensÃ£o de regiÃ£o:**
De:
	city,
	state,
	country
para: 
	***d_region***

**DimensÃ£o tempo:**
De:
	d_time,
	d_weekday
	d_week
	d_month
	d_year
para:
	**d_calendar**
		
**DimensÃ£o de TransaÃ§Ã£o:**

Gerar os tipos de transaÃ§Ãµes realizadas a partir das tabelas transfer_ins, transfer_outs, pix_moviments e investments e adiciona um id para favorecer o relacionamento com a tabela **f_transactions**.
	**d_transaction_type**
	
Essa dimensÃ¡o irÃ¡ favorecer a criaÃ§Ã£o de indicadores por tipo de movimento.
![image](https://user-images.githubusercontent.com/49626719/175829704-c85263c4-3c65-44d1-b1f5-054e35b253fa.png)


**DimesÃ£o de Status TransaÃ§Ã£o:**

Obter todos os status das transaÃ§Ãµes (completed, failed) das tabelas transfer_ins, transfer_outs, pix_moviments e investments. 
Gerar uma Ãºnica dimensÃ£o de status.
		**d_status_transaction**

**DimesÃ£o de Clientes:**

Para a criaÃ§Ã£o da tabela de clientes foi agreagdo algumas informaÃ§Ãµes da tabela de contas, pois como ambas possuem registros Ãºnicos, usei essa estratÃ©gia para 
diminuir o nÃºmero de dimensÃ³es e manter o relacionamento com a tabela fato com menos chaves estrangeiras possÃ­vel.

**CriaÃ§Ã£o da tabela Fato f_transactions:**

A tabela fato Ã© a consolidaÃ§Ã£o das chaves estrangeiras de todas as tabelas dimensÃ£o, usando sempre como referÃªncia a chave primÃ¡ria de cada uma.
UnificaÃ§Ã£o de:

	Transfer_ins
	Transfer_outs
	Pix_moviments
	Investments


## Como esse projeto funciona?

Abaixo irei apresentar a estrutura para executar toda a aÃ§Ã£o de criaÃ§Ã£o do modelo de dados, bem como a coleta dos arquivos originais em suas respectivas pastas para popular o banco jÃ¡ com os devidos relacionamentos.

### Passo a passo do funcionamento do projeto:

#### Estrutura do Projeto:

![image](https://user-images.githubusercontent.com/49626719/175793587-665a639a-8af3-49f4-91b0-4155c0d553e2.png)

#### Passo 1: Design da base de dados

CriaÃ§Ã£o dos arquivos de configuraÃ§Ã£o: 

â€¢	credentials_snow_flake.json
â€¢	credentials_snow_star.json
â€¢	tables.json


**Credenciais:**
ContÃ©m todas as informaÃ§Ãµes para a criaÃ§Ã£o do esquema de banco de dados:

	  - Host
	  - User
	  - Password
	  - Database

O argumento database precisa ser passado para nÃ£o gerar erro na criaÃ§Ã£o do modelo de dados.

**Tables:**

O arquivo de configuraÃ§Ã£o das tabelas server para manter a parte toda a estrutura de tabelas do banco, bem como os nomes das colunas, tipo de dados e os seus respectivos relacionamentos.

**Existem dois dicionÃ¡rios:**

â€¢	Snow_flake_tables (Original)
â€¢	Star_Schema_tables (Modelo proposto)
â€¢	Convert_to_datetime

*Sempre que quiser alterar as tabelas do modelo de dados, alterar relacionamentos e etc, Ã© no arquivo **tables.json** que vocÃª irÃ¡ fazer os ajustes.

***A lista convert_to_datetime, server para mapear todas as colunas de data que precisam de tratamento em seus respectivos UTCs.***

#### Passo 2: AÃ§Ã£o na base de dados criada

Leitura da pasta **raw_tables**, para criaÃ§Ã£o do banco de dados.
Essa parte do processo consiste em ler cada diretÃ³rio buscando por tipos especÃ­ficos de arquivos **(csv, xlsx, json)**.

1.	Percorrer os diretÃ³rios dentro do diretÃ³rio raw_tables e mapear os arquivos dentro de cada pasta e os inserir em uma lista de diretÃ³rios.
2.	Usa a lista para percorrer o diretÃ³rio novamente abrindo os arquivos e os consolidando, gerando assim um Ãºnico dataset.
3.	Converte o dataset gerado em lista e passa para a funÃ§Ã£o, que divide os dados em lotes para melhorar a performance da inserÃ§Ã£o no banco de dados.

**Obs.: Todo o processo de coleta dos arquivos, e execuÃ§Ã£o das queries no modelo snow_flake para inserir no modelo star estÃ¡ levando cerca de 12 minutos.**

### Log

Todo o processo Ã© armazenado em log para facilitar anÃ¡lise de erros e melhoria de performance futura.

***Parte do log da execuÃ§Ã£o do processo no banco de dados.***

![image](https://user-images.githubusercontent.com/49626719/175793986-9269d110-cc64-4e9b-b355-dc4cfd23898d.png)


### Ã‰ possÃ­vel reproduzir o projeto usando o arquivo requirements.txt
Existe tambÃ©m um backup das informaÃ§Ãµes do projeto no **GitHub** de forma privada.

### Problem Statement 3: Plano de MigraÃ§Ã£o

Para executar uma migraÃ§Ã£o das informaÃ§Ãµes de um banco para o outro sem que haja impacto na operaÃ§Ã£o Ã© necessÃ¡rio anÃ¡lisar os horÃ¡rios com menor volume de transaÃ§Ãµes no banco de dados, bem como avaliar a capacidade do servidor de lidar com a carga de trabalho oferecida pelo processo.
O intuito Ã© manter todos os seriviÃ§os em produÃ§Ã£o em execuÃ§Ã£o sem gargalos.

Ã‰ muito importante um alinhamento com as Ã¡reas de administraÃ§Ã£o de banco de dados, negÃ³cio e outras equipes que possam ser impactadas.
As consultas devem ser otimizadas para onerar o mÃ­nimo possÃ­vel os servidores, sejam eles em nuvem ou onpremise.

O plano de carga tambÃ©m deve ser levado em consideraÃ§Ã£o, qual seria a melhor abordagem, coleta de hora em hora, carga histÃ³rica e etc. 
Ã‰ necessÃ¡rio alinhar a estratÃ©gia com a equipe para levantamento de possÃ­veis gaps, dessa forma as chances do processo ser executado sem problemas fica muito mais alta.

Usar uma base de testes para fazer uma anÃ¡lise prÃ©via da performance do fluxo criado com um nÃºmero controlado de informaÃ§Ãµes, afim de estimar o impacto com o volume
real.

O plano de migraÃ§Ã£o segue o fluxo abaixo:
	1. Alimentar os arquivos de configuraÃ§Ã£o do banco de dados na pasta **\project\settings\**, pois sÃ£o eles que irÃ£o criar a conexÃ£o entre os bancos necessÃ¡rios.
	2.Ler as informaÃ§Ãµes no banco de dados nu_snow_flake atravÃ©s de consultas sql armazenadas no diretÃ³rio **\project\model\query** e editÃ¡-las afim de melhorar a performance delas, caso seja necessÃ¡rio.
	
	3. Conectar-se ao banco de dados nu_star_schema  e executar o insert seguindo a ordem das consultas dentro do diretÃ³rio de queries, para que os relacionamentos sejam criados corretamente.
	
	Scripts desse processo:
	
![image](https://user-images.githubusercontent.com/49626719/175793857-8720c7ac-fceb-4fb5-99a0-49526656180e.png)

	SÃ£o scripts com enfÃ¢se em leitura de arquivos em diretÃ³rio, criaÃ§Ã£o de conexÃ£o com dois bancos de dados diferentes e execuÃ§Ã£o de select em um e insert 
	no outro.
	
**Exemplo: Esse script Ã© reponsÃ¡vel por inserir as informaÃ§Ãµes retiradas do banco snow_flake, para o modelo star**
	
		def populate_tables(model: str) -> None:
			    # insert data into tables

			    # generate list to ordering insert
			    tbl_names = data_tables[model + '_tables']
			    inserts = []
			    for dict in tbl_names:
				try:
				    name = [tbl_name for tbl_name in dict.keys()]
				    inserts.append(*name)
				except AttributeError:
				    logger.error('You are trying to get key from a list.')

			    if model == 'snow_flake':
				# read raw_tables directory to concat files into just one
				# dataset
				for root, dirs, files in os.walk(RAW_TABLES_DIR):
				    for tbl_name in inserts:
					# searching for all files into directory
					list_paths = db_action.consolidate_path_files(
					    os.path.join(root, tbl_name))
					# receive a pandas dataframe to insert into the table from
					# dir name
					logger.info(f'Inserting data into {tbl_name}...')
					df = db_action.concat_dataset(list_paths)
					for column in df.columns:
					    # convert date in datetime
					    if column in data_tables['convert_to_datetime']:
						df[column] = df[column].apply(
						    dateutil.parser.parse)

					# clean none from transfer_ins and outs
					if tbl_name in ['transfer_ins', 'transfer_outs']:
					    try:
						df['transaction_completed_at'] = df['transaction_completed_at'].replace(
						    'None', 0)
					    except KeyError:
						logger.error("Key doesn't exist.")

					if tbl_name == 'pix_movements':
					    try:
						df['pix_completed_at'] = df['pix_completed_at'].replace(
						    'None', 0)
					    except KeyError:
						logger.error("Key doesn't exist.")

					if tbl_name == 'investments':
					    try:
						df = read_api.get_json_investments(list_paths)
						df['investment_completed_at_timestamp'] = df['investment_completed_at_timestamp'].apply(
						    dateutil.parser.parse)
					    except Exception as e:
						logger.error(f'Error --> {e}')

					# consolidate inserts limit 1000 rows to improve performance
					list_values = df.values.tolist()
					result_list_values = db_action.split_insert(
					    list_values=list_values, begin=0, step=1000)

					# call function to execute insert
					print('Please wait...')
					conn = db_design.db_conn(credentials=credentials_snow)
					db_action.execute_insert(
					    conn,
					    credentials_snow['database'],
					    tbl_name,
					    df.columns.tolist(),
					    result_list_values,
					)
			    else:
				# connect with two databases to performe select and then insert
				snow_conn = db_design.db_conn(credentials=credentials_snow)
				star_conn = db_design.db_conn(credentials=credentials_star)

				# process execution
				db_read_query.execute(snow_conn, star_conn,
						      credentials_star, QUERY_DIR)


### Problem Statement 4: Proposta de KPIs para o Pix

O pix Ã© um produto com uma alta de manda de transaÃ§Ãµes. Para acompanhar o desempenho desse produto eu sugiro a criaÃ§Ã£o dos seguintes indicadores:

VisÃ£o Gerencial

â€¢	Quantidade de transaÃ§Ãµes consolidadas por dia
â€¢	Quantidade de transaÃ§Ãµes consolidadas por mÃªs
â€¢	Percentual de crescimento de transaÃ§Ãµes em relaÃ§Ã£o aos demais produtos (transferÃªncias, investimentos e etc)
â€¢	Desempenho em relaÃ§Ã£o a meta

**Exemplo:**

![image](https://user-images.githubusercontent.com/49626719/175800943-6ab0e0bc-ae2d-45b8-9f8a-012a5b4eb1c2.png)


VisÃ£o AnalÃ­tica

â€¢	Quantidade de transaÃ§Ãµes por hora
â€¢	Quantidade de transaÃ§Ãµes por minuto
â€¢	Quantidade de transaÃ§Ãµes por segundo

**Exemplo:**

![image](https://user-images.githubusercontent.com/49626719/175800966-a2971a03-6b8c-47e8-8fde-91f733cbe754.png)


VisÃ£o Preditiva

â€¢	Essa visÃ£o irÃ¡ conter o resultado da prediÃ§Ã£o dos prÃ³ximos picos de transaÃ§Ãµes por
Minuto, segundo e hora.

O intuito Ã© efetuar um novo balanceamento dos recursos de servidores para o serviÃ§o nÃ£o ser impactado.

**Exemplo**

![image](https://user-images.githubusercontent.com/49626719/175801058-6e8931ca-23f9-49c0-bef5-d478ee988ce8.png)


### Problem Statement 5: FunÃ§Ã£o para calcular o retorno total de um investimento realizado

Abaixo segue o print do arquivo .csv gerado. 

Contas para serem calculados os retornos de investimento.

![image](https://user-images.githubusercontent.com/49626719/175793467-3d198199-483f-4d5e-90c4-7015f86ad23f.png)

 
Foi usado um script python para a leitura do arquivo investment_accounts_to_send.csv e uma funÃ§Ã£o para ler o json de investimentos investments_json com o intuito de gerar uma tabela e a partir daÃ­ usando o framework pandas do Python processar o cruzamento das contas com o arquivo de transaÃ§Ãµes.

Principais arquivos da pasta **return_of_investment**:
![image](https://user-images.githubusercontent.com/49626719/175830229-51c7e0a5-521b-4759-b44c-ca212ea472c6.png)

	- process.py 
		Arquivo principal. Executa todas as funÃ§Ãµes necessÃ¡rias para a geraÃ§Ã£o do arquivo final.
	- calculate.py
		Efetua os cÃ¡lculos abaixo:
		 - ð‘€ð‘œð‘£ð‘’ð‘šð‘’ð‘›ð‘¡ð‘  = ð‘ƒð‘Ÿð‘’ð‘£ð‘–ð‘œð‘¢ð‘  ð·ð‘Žð‘¦ ðµð‘Žð‘™ð‘Žð‘›ð‘ð‘’ + ð·ð‘’ð‘ð‘œð‘ ð‘–ð‘¡ âˆ’ ð‘Šð‘–ð‘¡â„Žð‘‘ð‘Ÿð‘Žð‘¤al
		 - ð¸ð‘›ð‘‘ ð‘œð‘“ ð·ð‘Žð‘¦ ð¼ð‘›ð‘ð‘œð‘šð‘’ = ð‘€ð‘œð‘£ð‘’ð‘šð‘’ð‘›ð‘¡ð‘  * ð¼ð‘›ð‘ð‘œð‘šð‘’ ð‘…ð‘Žð‘¡ð‘’
		 - ð´ð‘ð‘ð‘œð‘¢ð‘›ð‘¡ ð·ð‘Žð‘–ð‘™ð‘¦ ðµð‘Žð‘™ð‘Žð‘›ð‘ð‘’ = ð‘€ð‘œð‘£ð‘’ð‘šð‘’ð‘›ð‘¡ð‘  + ð¸ð‘›ð‘‘ ð‘œð‘“ ð·ð‘Žð‘¦ ð¼ð‘›ð‘ð‘œð‘šð‘’	
	- investment_income.csv
		Arquivo final gerado pelo processo. Traz o saldo diÃ¡rio de cada conta enviada.

***Resultado***

![image](https://user-images.githubusercontent.com/49626719/175830195-3fa06e39-73ec-4307-9a0f-408cc2d5bad1.png)


 ### Script Python para analisar as transaÃ§Ãµes:
 
			 def calculate_movements(list, i):
			    if i == 0:
				previous_d = 0
				deposit = list[i][3]
				withdrawal = list[i][4]
				movement = previous_d + deposit - withdrawal
				end_of_day_income = movement * 0.0001 if previous_d >= 0 else 0
				account_balance = movement + end_of_day_income

				list[i][5] = end_of_day_income
				list[i][6] = account_balance

				return list
			    else:
				previous_d = list[i - 1][6]
				deposit = list[i][3]
				withdrawal = list[i][4]
				movement = previous_d + deposit - withdrawal
				end_of_day_income = movement * 0.0001 if previous_d > 0 else 0
				account_balance = movement + end_of_day_income

				list[i][5] = end_of_day_income
				list[i][6] = account_balance

				return list
